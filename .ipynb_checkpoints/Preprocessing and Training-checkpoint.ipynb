{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebf89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d345b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "groups = os.listdir(data_dir)\n",
    "\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879c6de",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5eba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_face(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (227, 227))\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def preprocess_image_eye(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (60, 30))\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def preprocess_label(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        coordinates = [float(coord) for coord in file.readline().strip().split(',')]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53aa2eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 227 and the array at index 2 has size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m right_eye \u001b[38;5;241m=\u001b[39m preprocess_image_eye(right_eye_path)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Add features in a list\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m feature \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([original_image, cropped_face, left_eye, right_eye], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(feature)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Read and add label to a list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 227 and the array at index 2 has size 30"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    group_dir = os.path.join(data_dir, group)\n",
    "    if os.path.isdir(group_dir):\n",
    "        original_image_path = os.path.join(group_dir, 'original_image.jpg')\n",
    "        cropped_face_path = os.path.join(group_dir, 'cropped_face.jpg')\n",
    "        left_eye_path = os.path.join(group_dir, 'left_eye.jpg')\n",
    "        right_eye_path = os.path.join(group_dir, 'right_eye.jpg')\n",
    "        \n",
    "        original_image = preprocess_image_face(original_image_path)\n",
    "        cropped_face = preprocess_image_face(cropped_face_path)\n",
    "        left_eye = preprocess_image_eye(left_eye_path)\n",
    "        right_eye = preprocess_image_eye(right_eye_path)\n",
    "        \n",
    "        # Add features in a list\n",
    "        feature = np.concatenate([original_image, cropped_face, left_eye, right_eye], axis=-1)\n",
    "        features.append(feature)\n",
    "        \n",
    "        # Read and add label to a list\n",
    "        label_path = os.path.join(group_dir, 'labels.txt')\n",
    "        label = preprocess_label(label_path)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ccc06",
   "metadata": {},
   "source": [
    "## Shuffle and Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(features.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "features = features[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde11e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1bbef",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a25e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad8a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_input = layers.Input(shape=(original_image_height, original_image_width, original_image_channels))\n",
    "cropped_face_input = layers.Input(shape=(cropped_face_height, cropped_face_width, cropped_face_channels))\n",
    "left_eye_input = layers.Input(shape=(left_eye_height, left_eye_width, left_eye_channels))\n",
    "right_eye_input = layers.Input(shape=(right_eye_height, right_eye_width, right_eye_channels))\n",
    "\n",
    "conv1_original = layers.Conv2D(32, (3, 3), activation='relu')(original_image_input)\n",
    "pool1_original = layers.MaxPooling2D((2, 2))(conv1_original)\n",
    "conv2_original = layers.Conv2D(64, (3, 3), activation='relu')(pool1_original)\n",
    "pool2_original = layers.MaxPooling2D((2, 2))(conv2_original)\n",
    "conv3_original = layers.Conv2D(64, (3, 3), activation='relu')(pool2_original)\n",
    "flat1_original = layers.Flatten()(conv3_original)\n",
    "\n",
    "conv1_cropped = layers.Conv2D(32, (3, 3), activation='relu')(cropped_face_input)\n",
    "pool1_cropped = layers.MaxPooling2D((2, 2))(conv1_cropped)\n",
    "conv2_cropped = layers.Conv2D(64, (3, 3), activation='relu')(pool1_cropped)\n",
    "pool2_cropped = layers.MaxPooling2D((2, 2))(conv2_cropped)\n",
    "conv3_cropped = layers.Conv2D(64, (3, 3), activation='relu')(pool2_cropped)\n",
    "flat1_cropped = layers.Flatten()(conv3_cropped)\n",
    "\n",
    "conv1_left_eye = layers.Conv2D(32, (3, 3), activation='relu')(left_eye_input)\n",
    "pool1_left_eye = layers.MaxPooling2D((2, 2))(conv1_left_eye)\n",
    "conv2_left_eye = layers.Conv2D(64, (3, 3), activation='relu')(pool1_left_eye)\n",
    "pool2_left_eye = layers.MaxPooling2D((2, 2))(conv2_left_eye)\n",
    "conv3_left_eye = layers.Conv2D(64, (3, 3), activation='relu')(pool2_left_eye)\n",
    "flat1_left_eye = layers.Flatten()(conv3_left_eye)\n",
    "\n",
    "conv1_right_eye = layers.Conv2D(32, (3, 3), activation='relu')(right_eye_input)\n",
    "pool1_right_eye = layers.MaxPooling2D((2, 2))(conv1_right_eye)\n",
    "conv2_right_eye = layers.Conv2D(64, (3, 3), activation='relu')(pool1_right_eye)\n",
    "pool2_right_eye = layers.MaxPooling2D((2, 2))(conv2_right_eye)\n",
    "conv3_right_eye = layers.Conv2D(64, (3, 3), activation='relu')(pool2_right_eye)\n",
    "flat1_right_eye = layers.Flatten()(conv3_right_eye)\n",
    "\n",
    "concatenated = layers.concatenate([flat1_original, flat1_cropped, flat1_left_eye, flat1_right_eye])\n",
    "\n",
    "dense1 = layers.Dense(64, activation='relu')(concatenated)\n",
    "dense2 = layers.Dense(16, activation='relu')(dense1)\n",
    "#dense3 = layers.Dense(16, activation='relu')(desne2)\n",
    "\n",
    "output = layers.Dense(2)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.Model(inputs=[original_image_input, cropped_face_input, left_eye_input, right_eye_input],\n",
    "                     outputs=output)\n",
    "\n",
    "model1.compile(optimizer='adam', \n",
    "              loss='mse', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86670da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "original_image_input = layers.Input(shape=(original_image_height, original_image_width, original_image_channels))\n",
    "face_image_input = layers.Input(shape=(face_image_height, face_image_width, face_image_channels))\n",
    "left_eye_image_input = layers.Input(shape=(left_eye_image_height, left_eye_image_width, left_eye_image_channels))\n",
    "\n",
    "conv1_original = layers.Conv2D(32, (3, 3), activation='relu')(original_image_input)\n",
    "pool1_original = layers.MaxPooling2D((2, 2))(conv1_original)\n",
    "conv2_original = layers.Conv2D(64, (3, 3), activation='relu')(pool1_original)\n",
    "pool2_original = layers.MaxPooling2D((2, 2))(conv2_original)\n",
    "conv3_original = layers.Conv2D(64, (3, 3), activation='relu')(pool2_original)\n",
    "pool3_original = layers.MaxPooling2D((2, 2))(conv3_original)\n",
    "flatten_original = layers.Flatten()(pool3_origin)\n",
    "\n",
    "conv1_face = layers.Conv2D(32, (3, 3), activation='relu')(face_image_input)\n",
    "pool1_face = layers.MaxPooling2D((2, 2))(conv1_face)\n",
    "conv2_face = layers.Conv2D(64, (3, 3), activation='relu')(pool1_face)\n",
    "pool2_face = layers.MaxPooling2D((2, 2))(conv2_face)\n",
    "conv3_face = layers.Conv2D(64, (3, 3), activation='relu')(pool2_face)\n",
    "pool3_face = layers.MaxPooling2D((2, 2))(conv3_face)\n",
    "flatten_face = layers.Flatten()(pool3_face)\n",
    "\n",
    "conv1_left_eye = layers.Conv2D(32, (3, 3), activation='relu')(left_eye_image_input)\n",
    "pool1_left_eye = layers.MaxPooling2D((2, 2))(conv1_left_eye)\n",
    "conv2_left_eye = layers.Conv2D(64, (3, 3), activation='relu')(pool1_left_eye)\n",
    "pool2_left_eye = layers.MaxPooling2D((2, 2))(conv2_left_eye)\n",
    "conv3_left_eye = layers.Conv2D(64, (3, 3), activation='relu')(pool2_left_eye)\n",
    "pool3_left_eye = layers.MaxPooling2D((2, 2))(conv3_left_eye)\n",
    "flatten_left_eye = layers.Flatten()(pool3_left_eye)\n",
    "\n",
    "concatenated = layers.concatenate([flatten_original, flatten_face, flatten_left_eye])\n",
    "\n",
    "dense1 = layers.Dense(64, activation='relu')(concatenated)\n",
    "output = layers.Dense(2)(dense1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Model(inputs=[original_image_input, face_image_input, left_eye_image_input],\n",
    "                     outputs=output)\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f38d7",
   "metadata": {},
   "source": [
    "### Plot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bbee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model_plot.png')\n",
    "\n",
    "img = plt.imread('model_plot.png')\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304246e3",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit([X_train[:, :, :, :3], X_train[:, :, :, 3:6], X_train[:, :, :, 6:9], X_train[:, :, :, 9:]], \n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    validation_data=([X_test[:, :, :, :3], X_test[:, :, :, 3:6], X_test[:, :, :, 6:9], X_test[:, :, :, 9:]],\n",
    "                                    y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit([X_train[:, :, :, :3], X_train[:, :, :, 3:6], X_train[:, :, :, 6:9]], \n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    validation_data=([X_test[:, :, :, :3], X_test[:, :, :, 3:6], X_test[:, :, :, 6:9]],\n",
    "                                    y_test)) \n",
    "\n",
    "predictions2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy_report1 = accuracy_score(y_test, predictions1)\n",
    "classification1 = classification_report(y_test, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score1, classification1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
